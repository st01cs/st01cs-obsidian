
  
大型语言模型（LLM）正迅速从文本生成器转变为强大的问题解决者，但许多复杂开放任务仍需批判性思维、多源信息整合及可验证输出，传统单轮提示或检索增强生成难以胜任。深度研究（Deep Research, DR）应运而生，融合LLM推理与外部工具（如搜索引擎），使其成为自主研究代理，能完成复杂开放任务。  
  
本文系统梳理了DR领域的核心技术与挑战，提出了三阶段路线图：  
第一阶段“智能搜索”侧重精准检索和轻度合成；  
第二阶段“综合研究”强调多源证据整合与结构化长文生成；  
第三阶段“全栈AI科学家”迈向科学发现、假设生成与实验验证。  
  
DR系统包含四大关键组件：  
1. 查询规划——将复杂问题分解为可执行子任务，支持并行、顺序及树状规划策略，兼顾效率与逻辑依赖；  
2. 信息获取——结合词汇检索、语义检索及商业搜索引擎，同时支持多模态（文本、图表、表格）检索，提升信息丰富度与时效性；  
3. 记忆管理——涵盖记忆整合、索引、更新与遗忘，支持长期动态知识演化，区别于传统检索增强生成（RAG）中的静态记忆；  
4. 答案生成——综合上游信息，融合可信度加权、多代理协同与强化学习，确保长文连贯且证据充足，逐步迈向多模态展示（图表、音频、视频）输出。  
  
优化DR系统的实践路径包括：  
- 工作流提示设计，构建多代理协作框架（如Anthropic DeepResearch）；  
- 监督微调，通过强对弱蒸馏及自我迭代进化提升模型能力；  
- 端到端强化学习，针对单模块或整体流水线进行策略优化，提升检索决策与生成质量。  
  
评测方面，DR系统面临多维挑战：  
- 信息检索任务从单跳到多跳、多模态、动态网页交互环境演进；  
- 报告生成涵盖综述、长文、海报与幻灯片，强调内容完整性与结构合理性；  
- 科研辅助涵盖创意生成、实验执行、学术写作与同行评审，要求评估创新性和可靠性。  
  
未来挑战与展望：  
- 检索时机的精细判定仍待突破，避免过度或不足检索带来的性能下降；  
- 记忆系统需从被动存储向主动预测演化，结合认知科学设计结构化动态记忆；  
- 多轮强化学习训练存有不稳定风险，需探索更稳健的训练策略和奖励机制；  
- 长文逻辑一致性、创新与幻觉的界定、评估体系的偏见及效率问题亟需解决；  
- 创造力、公平性、安全性与可靠性是推动DR向通用智能迈进的关键议题。  
  
深度研究正引领大型语言模型迈向自主、可信、结构化的科学研究新纪元，期待其在多模态推理、自我进化记忆和智能强化学习等方向持续突破，推动AI辅助科研迈向更高水平。  
  
详细阅读请见论文链接：arxiv.org/abs/2512.02038