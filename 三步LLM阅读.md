I’m starting to get into a habit of reading everything (blogs, articles, book chapters,…) with LLMs. Usually pass 1 is manual, then pass 2 “explain/summarize”, pass 3 Q&A. I usually end up with a better/deeper understanding than if I moved on. Growing to among top use cases. On the flip side, if you’re a writer trying to explain/communicate something, we may increasingly see less of a mindset of “I’m writing this for another human” and more “I’m writing this for an LLM”. Because once an LLM “gets it”, it can then target, personalize and serve the idea to its user.  

我开始逐渐养成一种习惯：用 LLMs 阅读所有内容（博客、文章、书本章节等）。通常第一遍是手动阅读，第二遍让模型“解释/总结”，第三遍进行问答。这样做之后，我通常能获得比直接继续阅读更好的理解深度。这正逐渐成为最主流的使用场景之一。 反过来说，如果你是一名作者，试图解释或传达某种观点，我们可能会越来越看到这样一种心态转变：从“我写这个是给另一个普通人看”转变为“我写这个是给一个 LLM 看”。因为一旦 LLM “理解”了内容，它就能将这个想法精准地个性化并传递给最终用户。