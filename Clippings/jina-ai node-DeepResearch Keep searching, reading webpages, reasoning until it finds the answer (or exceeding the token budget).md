---
title: "jina-ai/node-DeepResearch: Keep searching, reading webpages, reasoning until it finds the answer (or exceeding the token budget)"
source: https://github.com/jina-ai/node-DeepResearch
author:
  - "[[nomagick]]"
published:
created: 2025-10-01
description: Keep searching, reading webpages, reasoning until it finds the answer (or exceeding the token budget) - jina-ai/node-DeepResearch
tags:
  - clippings
  - deepresearch
---
**[node-DeepResearch](https://github.com/jina-ai/node-DeepResearch)** Public

Keep searching, reading webpages, reasoning until it finds the answer (or exceeding the token budget)

[search.jina.ai](https://search.jina.ai/ "https://search.jina.ai")

[Apache-2.0 license](https://github.com/jina-ai/node-DeepResearch/blob/main/LICENSE)

[Open in github.dev](https://github.dev/) [Open in a new github.dev tab](https://github.dev/) [Open in codespace](https://github.com/codespaces/new/jina-ai/node-DeepResearch?resume=1)

<table><thead><tr><th colspan="2"><span>Name</span></th><th colspan="1"><span>Name</span></th><th><p><span>Last commit message</span></p></th><th colspan="1"><p><span>Last commit date</span></p></th></tr></thead><tbody><tr><td colspan="3"><p><span><a href="https://github.com/jina-ai/node-DeepResearch/commit/53963f264dce700fd58c6ad38a3841334daa35c0">saas: suspend llm token multiplier</a></span></p><p><span><a href="https://github.com/jina-ai/node-DeepResearch/commit/53963f264dce700fd58c6ad38a3841334daa35c0">53963f2</a> ·</span></p><p><a href="https://github.com/jina-ai/node-DeepResearch/commits/main/"><span><span><span>568 Commits</span></span></span></a></p></td></tr><tr><td colspan="2"><p><a href="https://github.com/jina-ai/node-DeepResearch/tree/main/.github">.github</a></p></td><td colspan="1"><p><a href="https://github.com/jina-ai/node-DeepResearch/tree/main/.github">.github</a></p></td><td><p><a href="https://github.com/jina-ai/node-DeepResearch/commit/b79727362675f738b4c8f6281f1b69286decb983">chore: refactor cd.yml for clarity and structure</a></p></td><td></td></tr><tr><td colspan="2"><p><a href="https://github.com/jina-ai/node-DeepResearch/tree/main/.vscode">.vscode</a></p></td><td colspan="1"><p><a href="https://github.com/jina-ai/node-DeepResearch/tree/main/.vscode">.vscode</a></p></td><td><p><a href="https://github.com/jina-ai/node-DeepResearch/commit/8af35c66408a72267cabfaebdd9d48ed8880b71c">jina-ai: billing for saas service (</a><a href="https://github.com/jina-ai/node-DeepResearch/pull/55">#55</a><a href="https://github.com/jina-ai/node-DeepResearch/commit/8af35c66408a72267cabfaebdd9d48ed8880b71c">)</a></p></td><td></td></tr><tr><td colspan="2"><p><a href="https://github.com/jina-ai/node-DeepResearch/tree/main/jina-ai">jina-ai</a></p></td><td colspan="1"><p><a href="https://github.com/jina-ai/node-DeepResearch/tree/main/jina-ai">jina-ai</a></p></td><td><p><a href="https://github.com/jina-ai/node-DeepResearch/commit/44dae8efb3d079f6e73884aaee63e02bfd4e8d86">feat: add serpCluster integration and schema</a></p></td><td></td></tr><tr><td colspan="2"><p><a href="https://github.com/jina-ai/node-DeepResearch/tree/main/src">src</a></p></td><td colspan="1"><p><a href="https://github.com/jina-ai/node-DeepResearch/tree/main/src">src</a></p></td><td><p><a href="https://github.com/jina-ai/node-DeepResearch/commit/53963f264dce700fd58c6ad38a3841334daa35c0">saas: suspend llm token multiplier</a></p></td><td></td></tr><tr><td colspan="2"><p><a href="https://github.com/jina-ai/node-DeepResearch/blob/main/.dockerignore">.dockerignore</a></p></td><td colspan="1"><p><a href="https://github.com/jina-ai/node-DeepResearch/blob/main/.dockerignore">.dockerignore</a></p></td><td><p><a href="https://github.com/jina-ai/node-DeepResearch/commit/8af35c66408a72267cabfaebdd9d48ed8880b71c">jina-ai: billing for saas service (</a><a href="https://github.com/jina-ai/node-DeepResearch/pull/55">#55</a><a href="https://github.com/jina-ai/node-DeepResearch/commit/8af35c66408a72267cabfaebdd9d48ed8880b71c">)</a></p></td><td></td></tr><tr><td colspan="2"><p><a href="https://github.com/jina-ai/node-DeepResearch/blob/main/.eslintrc.js">.eslintrc.js</a></p></td><td colspan="1"><p><a href="https://github.com/jina-ai/node-DeepResearch/blob/main/.eslintrc.js">.eslintrc.js</a></p></td><td><p><a href="https://github.com/jina-ai/node-DeepResearch/commit/44530a476070efbbe0be37c0f962da85bbaecdbd">llm-provider: google cloud vertex</a></p></td><td></td></tr><tr><td colspan="2"><p><a href="https://github.com/jina-ai/node-DeepResearch/blob/main/.gitignore">.gitignore</a></p></td><td colspan="1"><p><a href="https://github.com/jina-ai/node-DeepResearch/blob/main/.gitignore">.gitignore</a></p></td><td><p><a href="https://github.com/jina-ai/node-DeepResearch/commit/d5a31bce526a53c45b155275915777f16f3bb9c9">chore: update.gitignore, format config.json, add arxiv search functi…</a></p></td><td></td></tr><tr><td colspan="2"><p><a href="https://github.com/jina-ai/node-DeepResearch/blob/main/Dockerfile">Dockerfile</a></p></td><td colspan="1"><p><a href="https://github.com/jina-ai/node-DeepResearch/blob/main/Dockerfile">Dockerfile</a></p></td><td><p><a href="https://github.com/jina-ai/node-DeepResearch/commit/3d6e6f73ea1ac5124f0fb28d1e97e275130334a5">remove node memory limit</a></p></td><td></td></tr><tr><td colspan="2"><p><a href="https://github.com/jina-ai/node-DeepResearch/blob/main/LICENSE">LICENSE</a></p></td><td colspan="1"><p><a href="https://github.com/jina-ai/node-DeepResearch/blob/main/LICENSE">LICENSE</a></p></td><td><p><a href="https://github.com/jina-ai/node-DeepResearch/commit/0ef052296d9351c4ac0cee10ef32f7ebf22171e6">Create LICENSE</a></p></td><td></td></tr><tr><td colspan="2"><p><a href="https://github.com/jina-ai/node-DeepResearch/blob/main/README.md">README.md</a></p></td><td colspan="1"><p><a href="https://github.com/jina-ai/node-DeepResearch/blob/main/README.md">README.md</a></p></td><td><p><a href="https://github.com/jina-ai/node-DeepResearch/commit/aac0db67e4c87dde1060ef4cdea2940ae819019d">feat: add hostnames bw filter</a></p></td><td></td></tr><tr><td colspan="3"></td></tr></tbody></table>

## DeepResearch

[Official UI](https://search.jina.ai/) | [UI Code](https://github.com/jina-ai/deepsearch-ui) | [Stable API](https://jina.ai/deepsearch) | [Blog](https://jina.ai/news/a-practical-guide-to-implementing-deepsearch-deepresearch)

Keep searching, reading webpages, reasoning until an answer is found (or the token budget is exceeded). Useful for deeply investigating a query.

```
---
config:
  theme: mc
  look: handDrawn
---
flowchart LR
 subgraph Loop["until budget exceed"]
    direction LR
        Search["Search"]
        Read["Read"]
        Reason["Reason"]
  end
    Query(["Query"]) --> Loop
    Search --> Read
    Read --> Reason
    Reason --> Search
    Loop --> Answer(["Answer"])
```

## Blog Post

Whether you like this implementation or not, I highly recommend you to read DeepSearch/DeepResearch implementation guide I wrote, which gives you a gentle intro to this topic.

- [English Part I](https://jina.ai/news/a-practical-guide-to-implementing-deepsearch-deepresearch), [Part II](https://jina.ai/news/snippet-selection-and-url-ranking-in-deepsearch-deepresearch)
- [中文微信公众号 第一讲](https://mp.weixin.qq.com/s/-pPhHDi2nz8hp5R3Lm_mww), [第二讲](https://mp.weixin.qq.com/s/apnorBj4TZs3-Mo23xUReQ)
- [日本語: DeepSearch/DeepResearch 実装の実践ガイド](https://jina.ai/ja/news/a-practical-guide-to-implementing-deepsearch-deepresearch)

We host an online deployment of this **exact** codebase, which allows you to do a vibe-check; or use it as daily productivity tools.

[https://search.jina.ai](https://search.jina.ai/)

The official API is also available for you to use:

```
https://deepsearch.jina.ai/v1/chat/completions
```

Learn more about the API at [https://jina.ai/deepsearch](https://jina.ai/deepsearch)

## Install

```
git clone https://github.com/jina-ai/node-DeepResearch.git
cd node-DeepResearch
npm install
```

[安装部署视频教程 on Youtube](https://youtu.be/vrpraFiPUyA)

It is also available on npm but not recommended for now, as the code is still under active development.

## Usage

We use Gemini (latest `gemini-2.0-flash`) / OpenAI / [LocalLLM](https://github.com/jina-ai/#use-local-llm) for reasoning, [Jina Reader](https://jina.ai/reader) for searching and reading webpages, you can get a free API key with 1M tokens from jina.ai.

```
export GEMINI_API_KEY=...  # for gemini
# export OPENAI_API_KEY=... # for openai
# export LLM_PROVIDER=openai # for openai
export JINA_API_KEY=jina_...  # free jina api key, get from https://jina.ai/reader

npm run dev $QUERY
```

### Official Site

You can try it on [our official site](https://search.jina.ai/).

### Official API

You can also use [our official DeepSearch API](https://jina.ai/deepsearch):

```
https://deepsearch.jina.ai/v1/chat/completions
```

You can use it with any OpenAI-compatible client.

For the authentication Bearer, API key, rate limit, get from [https://jina.ai/deepsearch](https://jina.ai/deepsearch).

If you are building a web/local/mobile client that uses `Jina DeepSearch API`, here are some design guidelines:

- Our API is fully compatible with [OpenAI API schema](https://platform.openai.com/docs/api-reference/chat/create), this should greatly simplify the integration process. The model name is `jina-deepsearch-v1`.
- Our DeepSearch API is a reasoning+search grounding LLM, so it's best for questions that require deep reasoning and search.
- Two special tokens are introduced `<think>...</think>`. Please render them with care.
- Citations are often provided, and in [Github-flavored markdown footnote format](https://github.blog/changelog/2021-09-30-footnotes-now-supported-in-markdown-fields/), e.g. `[^1]`, `[^2]`,...
- Guide the user to get a Jina API key from [https://jina.ai](https://jina.ai/), with 1M free tokens for new API key.
- There are rate limits, [between 10RPM to 30RPM depending on the API key tier](https://jina.ai/contact-sales#rate-limit).
- [Download Jina AI logo here](https://jina.ai/logo-Jina-1024.zip)

## Demo

> was recorded with `gemini-1.5-flash`, the latest `gemini-2.0-flash` leads to much better results!

Query: `"what is the latest blog post's title from jina ai?"` 3 steps; answer is correct![![demo1](https://github.com/jina-ai/node-DeepResearch/raw/main/.github/visuals/demo.gif)](https://github.com/jina-ai/node-DeepResearch/blob/main/.github/visuals/demo.gif)

Query: `"what is the context length of readerlm-v2?"` 2 steps; answer is correct![![demo1](https://github.com/jina-ai/node-DeepResearch/raw/main/.github/visuals/demo3.gif)](https://github.com/jina-ai/node-DeepResearch/blob/main/.github/visuals/demo3.gif)

Query: `"list all employees from jina ai that u can find, as many as possible"` 11 steps; partially correct! but im not in the list:([![demo1](https://github.com/jina-ai/node-DeepResearch/raw/main/.github/visuals/demo2.gif)](https://github.com/jina-ai/node-DeepResearch/blob/main/.github/visuals/demo2.gif)

Query: `"who will be the biggest competitor of Jina AI"` 42 steps; future prediction kind, so it's arguably correct! atm Im not seeing `weaviate` as a competitor, but im open for the future "i told you so" moment.[![demo1](https://github.com/jina-ai/node-DeepResearch/raw/main/.github/visuals/demo4.gif)](https://github.com/jina-ai/node-DeepResearch/blob/main/.github/visuals/demo4.gif)

More examples:

```
# example: no tool calling 
npm run dev "1+1="
npm run dev "what is the capital of France?"

# example: 2-step
npm run dev "what is the latest news from Jina AI?"

# example: 3-step
npm run dev "what is the twitter account of jina ai's founder"

# example: 13-step, ambiguious question (no def of "big")
npm run dev "who is bigger? cohere, jina ai, voyage?"

# example: open question, research-like, long chain of thoughts
npm run dev "who will be president of US in 2028?"
npm run dev "what should be jina ai strategy for 2025?"
```

> Note, not every LLM works with our reasoning flow, we need those who support structured output (sometimes called JSON Schema output, object output) well. Feel free to purpose a PR to add more open-source LLMs to the working list.

If you use Ollama or LMStudio, you can redirect the reasoning request to your local LLM by setting the following environment variables:

```
export LLM_PROVIDER=openai  # yes, that's right - for local llm we still use openai client
export OPENAI_BASE_URL=http://127.0.0.1:1234/v1  # your local llm endpoint
export OPENAI_API_KEY=whatever  # random string would do, as we don't use it (unless your local LLM has authentication)
export DEFAULT_MODEL_NAME=qwen2.5-7b  # your local llm model name
```

If you have a GUI client that supports OpenAI API (e.g. [CherryStudio](https://docs.cherry-ai.com/), [Chatbox](https://github.com/Bin-Huang/chatbox)), you can simply config it to use this server.

[![demo1](https://github.com/jina-ai/node-DeepResearch/raw/main/.github/visuals/demo6.gif)](https://github.com/jina-ai/node-DeepResearch/blob/main/.github/visuals/demo6.gif)

Start the server:

```
# Without authentication
npm run serve

# With authentication (clients must provide this secret as Bearer token)
npm run serve --secret=your_secret_token
```

The server will start on [http://localhost:3000](http://localhost:3000/) with the following endpoint:

### POST /v1/chat/completions

```
# Without authentication
curl http://localhost:3000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "jina-deepsearch-v1",
    "messages": [
      {
        "role": "user",
        "content": "Hello!"
      }
    ]
  }'

# With authentication (when server is started with --secret)
curl http://localhost:3000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your_secret_token" \
  -d '{
    "model": "jina-deepsearch-v1",
    "messages": [
      {
        "role": "user",
        "content": "Hello!"
      }
    ],
    "stream": true
  }'
```

Response format:

```
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "created": 1677652288,
  "model": "jina-deepsearch-v1",
  "system_fingerprint": "fp_44709d6fcb",
  "choices": [{
    "index": 0,
    "message": {
      "role": "assistant",
      "content": "YOUR FINAL ANSWER"
    },
    "logprobs": null,
    "finish_reason": "stop"
  }],
  "usage": {
    "prompt_tokens": 9,
    "completion_tokens": 12,
    "total_tokens": 21
  }
}
```

For streaming responses (stream: true), the server sends chunks in this format:

```
{
  "id": "chatcmpl-123",
  "object": "chat.completion.chunk",
  "created": 1694268190,
  "model": "jina-deepsearch-v1",
  "system_fingerprint": "fp_44709d6fcb",
  "choices": [{
    "index": 0,
    "delta": {
      "content": "..."
    },
    "logprobs": null,
    "finish_reason": null
  }]
}
```

Note: The think content in streaming responses is wrapped in XML tags:

```
<think>
[thinking steps...]
</think>
[final answer]
```

## Docker Setup

To build the Docker image for the application, run the following command:

```
docker build -t deepresearch:latest .
```

To run the Docker container, use the following command:

```
docker run -p 3000:3000 --env GEMINI_API_KEY=your_gemini_api_key --env JINA_API_KEY=your_jina_api_key deepresearch:latest
```

### Docker Compose

You can also use Docker Compose to manage multi-container applications. To start the application with Docker Compose, run:

```
docker-compose up
```

Not sure a flowchart helps, but here it is:

```
flowchart TD
    Start([Start]) --> Init[Initialize context & variables]
    Init --> CheckBudget{Token budget<br/>exceeded?}
    CheckBudget -->|No| GetQuestion[Get current question<br/>from gaps]
    CheckBudget -->|Yes| BeastMode[Enter Beast Mode]

    GetQuestion --> GenPrompt[Generate prompt]
    GenPrompt --> ModelGen[Generate response<br/>using Gemini]
    ModelGen --> ActionCheck{Check action<br/>type}

    ActionCheck -->|answer| AnswerCheck{Is original<br/>question?}
    AnswerCheck -->|Yes| EvalAnswer[Evaluate answer]
    EvalAnswer --> IsGoodAnswer{Is answer<br/>definitive?}
    IsGoodAnswer -->|Yes| HasRefs{Has<br/>references?}
    HasRefs -->|Yes| End([End])
    HasRefs -->|No| GetQuestion
    IsGoodAnswer -->|No| StoreBad[Store bad attempt<br/>Reset context]
    StoreBad --> GetQuestion

    AnswerCheck -->|No| StoreKnowledge[Store as intermediate<br/>knowledge]
    StoreKnowledge --> GetQuestion

    ActionCheck -->|reflect| ProcessQuestions[Process new<br/>sub-questions]
    ProcessQuestions --> DedupQuestions{New unique<br/>questions?}
    DedupQuestions -->|Yes| AddGaps[Add to gaps queue]
    DedupQuestions -->|No| DisableReflect[Disable reflect<br/>for next step]
    AddGaps --> GetQuestion
    DisableReflect --> GetQuestion

    ActionCheck -->|search| SearchQuery[Execute search]
    SearchQuery --> NewURLs{New URLs<br/>found?}
    NewURLs -->|Yes| StoreURLs[Store URLs for<br/>future visits]
    NewURLs -->|No| DisableSearch[Disable search<br/>for next step]
    StoreURLs --> GetQuestion
    DisableSearch --> GetQuestion

    ActionCheck -->|visit| VisitURLs[Visit URLs]
    VisitURLs --> NewContent{New content<br/>found?}
    NewContent -->|Yes| StoreContent[Store content as<br/>knowledge]
    NewContent -->|No| DisableVisit[Disable visit<br/>for next step]
    StoreContent --> GetQuestion
    DisableVisit --> GetQuestion

    BeastMode --> FinalAnswer[Generate final answer] --> End
```

## Releases 7

[\+ 6 releases](https://github.com/jina-ai/node-DeepResearch/releases)

## Languages

- [TypeScript 98.9%](https://github.com/jina-ai/node-DeepResearch/search?l=typescript)
- Other 1.1%