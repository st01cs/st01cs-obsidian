---
title: "OpenPipe/open_deep_research_training: Training setup for Langchain's Open Deep Research"
source: https://github.com/OpenPipe/open_deep_research_training
author:
  - "[[arcticfly]]"
published:
created: 2025-10-01
description: Training setup for Langchain's Open Deep Research. Contribute to OpenPipe/open_deep_research_training development by creating an account on GitHub.
tags:
  - clippings
  - langgraph
  - ART
  - agent
  - deepresearch
---
**[open\_deep\_research\_training](https://github.com/OpenPipe/open_deep_research_training)** Public

Training setup for Langchain's Open Deep Research

[MIT license](https://github.com/OpenPipe/open_deep_research_training/blob/main/LICENSE)

[Open in github.dev](https://github.dev/) [Open in a new github.dev tab](https://github.dev/) [Open in codespace](https://github.com/codespaces/new/OpenPipe/open_deep_research_training?resume=1)

<table><thead><tr><th colspan="2"><span>Name</span></th><th colspan="1"><span>Name</span></th><th><p><span>Last commit message</span></p></th><th colspan="1"><p><span>Last commit date</span></p></th></tr></thead><tbody><tr><td colspan="3"><p><span><a href="https://github.com/OpenPipe/open_deep_research_training/commit/5a4b857b204d88e08de53fd86c4d16632664a6df">Update README to reflect new notebook path</a></span></p><p><span><a href="https://github.com/OpenPipe/open_deep_research_training/commit/5a4b857b204d88e08de53fd86c4d16632664a6df">5a4b857</a> Â·</span></p><p><a href="https://github.com/OpenPipe/open_deep_research_training/commits/main/"><span><span><span>20 Commits</span></span></span></a></p></td></tr><tr><td colspan="2"><p><a href="https://github.com/OpenPipe/open_deep_research_training/tree/main/charts">charts</a></p></td><td colspan="1"><p><a href="https://github.com/OpenPipe/open_deep_research_training/tree/main/charts">charts</a></p></td><td><p><a href="https://github.com/OpenPipe/open_deep_research_training/commit/9f67a70388dd75f86e2e5b2f16bd34d6e50e3370">Bar chart</a></p></td><td></td></tr><tr><td colspan="2"><p><a href="https://github.com/OpenPipe/open_deep_research_training/tree/main/deep_research_bench">deep_research_bench</a></p></td><td colspan="1"><p><a href="https://github.com/OpenPipe/open_deep_research_training/tree/main/deep_research_bench">deep_research_bench</a></p></td><td><p><a href="https://github.com/OpenPipe/open_deep_research_training/commit/ea4366a3c01075cd5c8bd0b7dccc32fd98d9565c">Adding bench</a></p></td><td></td></tr><tr><td colspan="2"><p><a href="https://github.com/OpenPipe/open_deep_research_training/tree/main/evaluate">evaluate</a></p></td><td colspan="1"><p><a href="https://github.com/OpenPipe/open_deep_research_training/tree/main/evaluate">evaluate</a></p></td><td><p><a href="https://github.com/OpenPipe/open_deep_research_training/commit/ed3502dffd55faa0ee26e2f6c450c3157b1a9874">benchmark scipt</a></p></td><td></td></tr><tr><td colspan="2"><p><a href="https://github.com/OpenPipe/open_deep_research_training/tree/main/examples">examples</a></p></td><td colspan="1"><p><a href="https://github.com/OpenPipe/open_deep_research_training/tree/main/examples">examples</a></p></td><td><p><a href="https://github.com/OpenPipe/open_deep_research_training/commit/b4f718021414e31a48149336ec8b0624dd1b9704">init</a></p></td><td></td></tr><tr><td colspan="2"><p><a href="https://github.com/OpenPipe/open_deep_research_training/tree/main/licenses">licenses</a></p></td><td colspan="1"><p><a href="https://github.com/OpenPipe/open_deep_research_training/tree/main/licenses">licenses</a></p></td><td><p><a href="https://github.com/OpenPipe/open_deep_research_training/commit/ee51d83e1f0d6416b49cc00d66fd9f7547ff94be">Add notices and licenses</a></p></td><td></td></tr><tr><td colspan="2"><p><a href="https://github.com/OpenPipe/open_deep_research_training/tree/main/src">src</a></p></td><td colspan="1"><p><a href="https://github.com/OpenPipe/open_deep_research_training/tree/main/src">src</a></p></td><td><p><a href="https://github.com/OpenPipe/open_deep_research_training/commit/b4f718021414e31a48149336ec8b0624dd1b9704">init</a></p></td><td></td></tr><tr><td colspan="2"><p><a href="https://github.com/OpenPipe/open_deep_research_training/tree/main/tests">tests</a></p></td><td colspan="1"><p><a href="https://github.com/OpenPipe/open_deep_research_training/tree/main/tests">tests</a></p></td><td><p><a href="https://github.com/OpenPipe/open_deep_research_training/commit/b4f718021414e31a48149336ec8b0624dd1b9704">init</a></p></td><td></td></tr><tr><td colspan="2"><p><a href="https://github.com/OpenPipe/open_deep_research_training/blob/main/.env.example">.env.example</a></p></td><td colspan="1"><p><a href="https://github.com/OpenPipe/open_deep_research_training/blob/main/.env.example">.env.example</a></p></td><td><p><a href="https://github.com/OpenPipe/open_deep_research_training/commit/4c7bce1a36692a27c65080dcdfa53b38ab0f868e">Add more instructions on getting set up</a></p></td><td></td></tr><tr><td colspan="2"><p><a href="https://github.com/OpenPipe/open_deep_research_training/blob/main/.gitignore">.gitignore</a></p></td><td colspan="1"><p><a href="https://github.com/OpenPipe/open_deep_research_training/blob/main/.gitignore">.gitignore</a></p></td><td><p><a href="https://github.com/OpenPipe/open_deep_research_training/commit/b4f718021414e31a48149336ec8b0624dd1b9704">init</a></p></td><td></td></tr><tr><td colspan="2"><p><a href="https://github.com/OpenPipe/open_deep_research_training/blob/main/CONFIGURING_AWS.md">CONFIGURING_AWS.md</a></p></td><td colspan="1"><p><a href="https://github.com/OpenPipe/open_deep_research_training/blob/main/CONFIGURING_AWS.md">CONFIGURING_AWS.md</a></p></td><td><p><a href="https://github.com/OpenPipe/open_deep_research_training/commit/4c7bce1a36692a27c65080dcdfa53b38ab0f868e">Add more instructions on getting set up</a></p></td><td></td></tr><tr><td colspan="3"></td></tr></tbody></table>

This tutorial demonstrates how to train your own deep research agent using GRPO to exceed Sonnet 4's performance. Specifically, you will be using the [ART](https://github.com/OpenPipe/ART) library to specialize Qwen 2.5 14B for [Langchain's open deep research](https://github.com/langchain-ai/open_deep_research) framework, and will evaluate your agent's performance using [DeepResearch Bench: A Comprehensive Benchmark for Deep Research Agents](https://github.com/Ayanami0730/deep_research_bench). In addition to the GRPO training step, you will also run an initial SFT training run to improve the model's baseline performance.

The chart below shows the accuracy of a Qwen 2.5 14B Instruct model (the same model you will be training) as it learns to perform deep research, eventually exceeding the performance of GPT-4.1 and Sonnet 4. With any luck, your model will be able to do the same!

[![](https://github.com/OpenPipe/open_deep_research_training/raw/main/charts/accuracy-training-progress.svg)](https://github.com/OpenPipe/open_deep_research_training/blob/main/charts/accuracy-training-progress.svg)

## Getting Started

If you haven't already, install `uv` by following the instructions [here](https://docs.astral.sh/uv/getting-started/installation/).

Then install the project dependencies by running `uv sync`.

We'll be using `LocalBackend` to manage the GPU that your model will be trained on. In order to provision a GPU for your training run, you'll need to have SkyPilot installed on your machine and provide it with the credentials to spin up machines on at least one infra provider.

We recommend using RunPod because of their ease of use, but any infra provider that SkyPilot [supports](https://docs.skypilot.co/en/latest/overview.html#bringing-your-infra) will work.

Follow RunPod's **Getting Started** guide [here](https://docs.runpod.io/integrations/skypilot/). You'll have to provide a credit card to use RunPod, but you'll only pay for the time your GPUs are running.

Copy `.env.example` to `.env` at the root of the repository, and fill in the values for the environment variables. If you're unsure about any of the values, refer to [ENV\_INSTRUCTIONS.md](https://github.com/OpenPipe/open_deep_research_training/blob/main/ENV_INSTRUCTIONS.md).

You'll want to run these scripts in this order:

```
uv run collect_sft.py # Collect samples for your sft training run. ~1 Hour
uv run run_sft.py # Run your sft training run. ~1 Hour
uv run run_train.py # Run your rl training run. >1 Day
```

Run the benchmark script in the evaluate folder with the models you want to benchmark:

```
uv run evaluate/benchmark_model.py
```

Then run the `evaluate/display_benchmarks.ipynb` notebook to display the results.

### Modifications

We modified the DeepResearch Bench repo to add a new `run_single_race_bench.py` which allows you to run a single benchmark at a time, needed for running RL runs.

We modified the Open Deep Research repo to change the search to use Tavily's advanced search answering to enable training models with smaller context windows.

### Acknowledgements

Huge thanks to the [LangChain](https://github.com/langchain-ai/langchain) and [Tavily](https://github.com/tavily-ai) teams for collaborating on this project and providing the services that the agent is built on. Additionally, we greatly appreciate the overall support, feedback, and adoption that [ART](https://github.com/OpenPipe/ART) has received from the open source community.

## Releases

No releases published

## Packages

No packages published  

## Languages

- [Python 60.0%](https://github.com/OpenPipe/open_deep_research_training/search?l=python)
- [Jupyter Notebook 39.5%](https://github.com/OpenPipe/open_deep_research_training/search?l=jupyter-notebook)
- [Shell 0.5%](https://github.com/OpenPipe/open_deep_research_training/search?l=shell)