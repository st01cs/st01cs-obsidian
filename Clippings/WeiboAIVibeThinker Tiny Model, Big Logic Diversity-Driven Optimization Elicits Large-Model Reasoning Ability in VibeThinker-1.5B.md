---
title: "WeiboAI/VibeThinker: Tiny Model, Big Logic: Diversity-Driven Optimization Elicits Large-Model Reasoning Ability in VibeThinker-1.5B"
source: "https://github.com/WeiboAI/VibeThinker"
author:
  - "[[GitHub]]"
published:
created: 2025-11-14
description: "Tiny Model, Big Logic: Diversity-Driven Optimization Elicits Large-Model Reasoning Ability in VibeThinker-1.5B - WeiboAI/VibeThinker"
tags:
  - "clippings"
---
å¾®åšAIå¼€æº VibeThinker-1.5Bï¼šå°æ¨¡å‹ä¹Ÿå¯ä»¥æœ‰å¤§æ™ºæ…§  
ç›®å‰ä¸šç•Œæœ€å¼ºå¤§æ¨¡å‹å‚æ•°é‡å¤§éƒ½è¶…è¿‡äº†1Tï¼Œç”šè‡³å‡ºç°äº†2Tè§„æ¨¡çš„æ¨¡å‹ï¼Œæ˜¯å¦åªæœ‰å·¨é‡å‚æ•°æ¨¡å‹æ‰æœ‰é«˜åº¦çš„æ™ºèƒ½ï¼Ÿæ˜¯å¦åªæœ‰å°‘é‡ç§‘æŠ€å·¨å¤´æ‰æœ‰èƒ½åŠ›åšå¤§æ¨¡å‹ï¼Ÿ  
  
VibeThinker-1.5Bï¼Œæ­£æ˜¯å¾®åšAIå¯¹æ­¤é—®é¢˜ç»™å‡ºçš„å¦å®šç­”æ¡ˆï¼Œå®ƒè¯æ˜äº†å°æ¨¡å‹ä¹Ÿå¯ä»¥æœ‰é«˜æ™ºå•†ã€‚è¿™æ„å‘³ç€åšæœ€å¼ºå¤§æ¨¡å‹ä¸å†åƒä¼ ç»Ÿè§‚å¿µä»¥ä¸ºçš„é‚£æ ·ä¸»è¦ä¾èµ–æ¨é«˜å‚æ•°é‡ï¼Œä¹Ÿå¯ä»¥é€šè¿‡å·§å¦™çš„ç®—æ³•è®¾è®¡æ¥åšåˆ°è¿™ä¸€ç‚¹ã€‚  
  
è¿™æ¬¾æ¨¡å‹ä»…æœ‰1.5B(15äº¿)å‚æ•°ï¼Œç»è¿‡å¾®åšAIç ”å‘äººå‘˜æå‡ºçš„åˆ›æ–°â€œé¢‘è°±åˆ°ä¿¡å·åŸç†â€ï¼ˆSSPï¼‰æ–¹æ³•è®­ç»ƒåï¼Œå…¶æ•ˆæœå ªç§°é¢ è¦†ï¼šVibeThinkeråœ¨AIME24ã€AIME25ä»¥åŠHMMT25ä¸‰ä¸ªé«˜éš¾åº¦æ•°å­¦æµ‹è¯•é›†ä¸Šçš„è¡¨ç°ï¼Œè¶…è¶Šäº†å‚æ•°é‡è¶…å…¶400å€çš„æ¨¡å‹DeepSeek-R1-0120ç‰ˆæœ¬ï¼ˆæ¨¡å‹å¤§å°671Bï¼‰ï¼Œä¸è§„æ¨¡ä¸º456Bçš„MiniMax-M1æ•ˆæœæ¥è¿‘æˆ–ç›¸å½“ï¼›åœ¨LiveCodeBench v6ï¼ˆç¼–ç¨‹ç®—æ³•é¢˜æµ‹è¯•é›†ï¼‰ä¸­çš„æˆç»©ï¼ŒæˆåŠŸè¿½å¹³å‚æ•°é‡æ•°è¶…å…¶æ•°åå€çš„æ¨¡å‹ï¼Œæ¯”å¦‚æ¬§æ´²é¢†å…ˆAIä¼ä¸šMinstral.AIçš„æ·±åº¦æ€è€ƒæ¨¡å‹Magistral-Medium-2506ç‰ˆæœ¬ã€‚  
  
VibeThinkerèƒ½åŠ›å¼ºå¤§ä¸é å †å‚æ•°ï¼Œè€Œæ˜¯æºäºå¾®åšç ”å‘äººå‘˜æå‡ºçš„SSPè®­ç»ƒç†å¿µï¼Œå³åœ¨å­¦ä¹ é˜¶æ®µå…ˆé¼“åŠ±æ¨¡å‹å‘æ•£æ¢ç´¢æ‰€æœ‰å¯èƒ½çš„è§£é¢˜è·¯å¾„ï¼Œè€Œéä¸€å‘³å…³æ³¨æ­£ç¡®ç‡ï¼›éšåï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ è¿›è¡Œé«˜æ•ˆç­–ç•¥ä¼˜åŒ–ï¼Œç²¾å‡†é”å®šæ­£ç¡®è·¯å¾„ï¼Œå°†æ¨¡å‹æ€§èƒ½æå‡è‡³æè‡´ã€‚  
  
æ¨¡å‹çš„å•æ¬¡â€œåè®­ç»ƒâ€ï¼ˆPost-Trainingï¼‰æˆæœ¬ä¸è¶³8000ç¾å…ƒï¼Œä¸æ­¤å¯¹åº”ï¼ŒDeepSeek-R1å’ŒMiniMax-M1çš„åè®­ç»ƒæˆæœ¬åˆ†åˆ«æ˜¯29ä¸‡åŠ53ä¸‡ç¾å…ƒï¼Œé™ä½äº†å‡ åå€ã€‚  
  
VibeThinker-1.5Bçš„å¼€æºï¼Œæ—¨åœ¨ä¸ºå…¨çƒè®¡ç®—èµ„æºæœ‰é™çš„ä¸­å‹ä¼ä¸šåŠé«˜æ ¡ç ”ç©¶å›¢é˜Ÿï¼Œæä¾›ä¸€æ¡é«˜æ€§ä»·æ¯”çš„ç ”å‘æ–°è·¯å¾„ï¼Œä½¿å¾—äººäººéƒ½å¯ä»¥è®­ç»ƒæœ€å‰æ²¿çš„å¤§æ¨¡å‹ï¼Œè€Œä¸æ˜¯åƒä¹‹å‰ä¸€æ ·è¢«æ’æ–¥åœ¨å¤–ï¼Œè¿™å¯¹äºä¸šç•ŒæŠ€æœ¯è¿›æ­¥è‡³å…³é‡è¦ã€‚

Tiny Model, Big Logic: Diversity-Driven Optimization Elicits Large-Model Reasoning Ability in VibeThinker-1.5B

[MIT license](https://github.com/WeiboAI/VibeThinker/blob/main/LICENSE)

[Open in github.dev](https://github.dev/) [Open in a new github.dev tab](https://github.dev/) [Open in codespace](https://github.com/codespaces/new/WeiboAI/VibeThinker?resume=1)

<table><thead><tr><th colspan="2"><span>Name</span></th><th colspan="1"><span>Name</span></th><th><p><span>Last commit message</span></p></th><th colspan="1"><p><span>Last commit date</span></p></th></tr></thead><tbody><tr><td colspan="3"><p><span><a href="https://github.com/WeiboAI/VibeThinker/commit/47bec8a977510d5abc26d8f45ad39af843425a01">Add.gitignore to ignore.DS_Store files</a></span></p><p><span><a href="https://github.com/WeiboAI/VibeThinker/commit/47bec8a977510d5abc26d8f45ad39af843425a01">47bec8a</a> Â·</span></p><p><a href="https://github.com/WeiboAI/VibeThinker/commits/main/"><span><span><span>50 Commits</span></span></span></a></p></td></tr><tr><td colspan="2"><p><a href="https://github.com/WeiboAI/VibeThinker/tree/main/eval">eval</a></p></td><td colspan="1"><p><a href="https://github.com/WeiboAI/VibeThinker/tree/main/eval">eval</a></p></td><td><p><a href="https://github.com/WeiboAI/VibeThinker/commit/54a599be0834b3a02d7cf8c6af4009eb4cb4ac2a">Remove existing.DS_Store files from tracking</a></p></td><td></td></tr><tr><td colspan="2"><p><a href="https://github.com/WeiboAI/VibeThinker/tree/main/figures">figures</a></p></td><td colspan="1"><p><a href="https://github.com/WeiboAI/VibeThinker/tree/main/figures">figures</a></p></td><td><p><a href="https://github.com/WeiboAI/VibeThinker/commit/86435589e866835166bb3b4cd7ec85929c926c89">update figure</a></p></td><td></td></tr><tr><td colspan="2"><p><a href="https://github.com/WeiboAI/VibeThinker/blob/main/.gitignore">.gitignore</a></p></td><td colspan="1"><p><a href="https://github.com/WeiboAI/VibeThinker/blob/main/.gitignore">.gitignore</a></p></td><td><p><a href="https://github.com/WeiboAI/VibeThinker/commit/47bec8a977510d5abc26d8f45ad39af843425a01">Add.gitignore to ignore.DS_Store files</a></p></td><td></td></tr><tr><td colspan="2"><p><a href="https://github.com/WeiboAI/VibeThinker/blob/main/LICENSE">LICENSE</a></p></td><td colspan="1"><p><a href="https://github.com/WeiboAI/VibeThinker/blob/main/LICENSE">LICENSE</a></p></td><td><p><a href="https://github.com/WeiboAI/VibeThinker/commit/7c4b892f6e9fc99854d26ae748cbc8732de89bfd">Initial commit</a></p></td><td></td></tr><tr><td colspan="2"><p><a href="https://github.com/WeiboAI/VibeThinker/blob/main/README.md">README.md</a></p></td><td colspan="1"><p><a href="https://github.com/WeiboAI/VibeThinker/blob/main/README.md">README.md</a></p></td><td><p><a href="https://github.com/WeiboAI/VibeThinker/commit/eba5715b2933a626793408634034374ece61fef7">add news</a></p></td><td></td></tr><tr><td colspan="2"><p><a href="https://github.com/WeiboAI/VibeThinker/blob/main/VibeThinker-1.5B.pdf">VibeThinker-1.5B.pdf</a></p></td><td colspan="1"><p><a href="https://github.com/WeiboAI/VibeThinker/blob/main/VibeThinker-1.5B.pdf">VibeThinker-1.5B.pdf</a></p></td><td><p><a href="https://github.com/WeiboAI/VibeThinker/commit/34ac7a3f0034379da3ca93fde9a678c7b3e83afd">251107</a></p></td><td></td></tr><tr><td colspan="3"></td></tr></tbody></table>

## VibeThinker

[![](https://github.com/WeiboAI/VibeThinker/raw/main/figures/logo.png)](https://github.com/WeiboAI/VibeThinker/blob/main/figures/logo.png)

ğŸ¤— [Hugging Face](https://huggingface.co/WeiboAI) | ğŸ¤– [Model Scope](https://modelscope.cn/organization/WeiboAI) Â  | ğŸ“„ [Techical Report](https://huggingface.co/papers/2511.06221) | ğŸ† [arxiv paper](https://arxiv.org/abs/2511.06221)

## Introduction

VibeThinker-1.5B is a 1.5B-parameter dense model that challenges the prevailing notion that small models inherently lack robust reasoning capabilities. Developed with an innovative post-training methodology centered on the **"Spectrum-to-Signal Principle (SSP)"**, VibeThinker-1.5B demonstrates superior reasoning capabilities compared to closed-source models Magistral Medium and Claude Opus 4, while achieving performance on par with open-source models like GPT OSS-20B Medium.

Most remarkably, VibeThinker-1.5B surpasses the initial DeepSeek R1 modelâ€”which is over 400 times largerâ€”across three challenging mathematical benchmarks: AIME24 (80.3 vs. 79.8), AIME25 (74.4 vs. 70.0), and HMMT25 (50.4 vs. 41.7).

[![](https://github.com/WeiboAI/VibeThinker/raw/main/figures/vibethinker_eval2.png)](https://github.com/WeiboAI/VibeThinker/blob/main/figures/vibethinker_eval2.png)

## News

\[2025.11.11\] ğŸ‰ğŸ‰ğŸ‰ VibeThinker-1.5B is now open source! The model weights and technical report can be accessed via the links at the top.

\[2025.11.05\] ğŸ“¢ğŸ“¢ğŸ“¢ VibeThinker-1.5B will be open-sourced soon. Stay tuned!

## Key Features

- **Ultra-Efficient**: VibeThinker-1.5B redefines the efficiency frontier for reasoning models, achieving state-of-the-art performance in mathematical and coding tasks with only 1.5B parametersâ€”100Ã— to 600Ã— smaller than giants like Kimi K2 (1000B+) and DeepSeek R1(671B).

[![](https://github.com/WeiboAI/VibeThinker/raw/main/figures/am25_1.5B.png)](https://github.com/WeiboAI/VibeThinker/blob/main/figures/am25_1.5B.png)

- **Innovative Methodology**: We propose an innovative post-training technique centered on the â€œSpectrum-to-Signal Principle (SSP)â€. This framework systematically enhances output diversity by first employing a â€œTwo-Stage Diversity-Exploring Distillationâ€ in the SFT phase to generate a broad spectrum of solutions, followed by the â€œMaxEnt-Guided Policy Optimization (MGPO)â€ framework in the RL phase to amplify the correct signal.

[![](https://github.com/WeiboAI/VibeThinker/raw/main/figures/technicalArchitecture1.png)](https://github.com/WeiboAI/VibeThinker/blob/main/figures/technicalArchitecture1.png)

- **Outstanding Capabilities**: Despite a substantial parameter gapâ€”competing with models 10 to hundreds of times largerâ€”our 1.5B model demonstrates remarkable performance. On the AIME24, AIME25, and HMMT25 benchmarks, it surpasses open-source contenders like DeepSeek R1-0120 and GPT-OSS-20B-Medium, while achieving results comparable to MiniMax-M1.

[![](https://github.com/WeiboAI/VibeThinker/raw/main/figures/Performence1.png)](https://github.com/WeiboAI/VibeThinker/blob/main/figures/Performence1.png)

- **Cost-Effective**: While state-of-the-art models like DeepSeek R1 and MiniMax-M1 incur post-training costs of $294K and $535K respectively, our approach achieves this for just $7,800. This represents a reduction by a factor of â€œ30 to 60â€, fundamentally changing the economics of developing high-performance reasoning models.

[![](https://github.com/WeiboAI/VibeThinker/raw/main/figures/Cost.png)](https://github.com/WeiboAI/VibeThinker/blob/main/figures/Cost.png)

## Model Downloads

The model checkpoint is available at: [Hugging Face](https://huggingface.co/WeiboAI/VibeThinker-1.5B) and [ModelScope](https://modelscope.cn/models/WeiboAI/VibeThinker-1.5B).

## Eval

If you wish to reproduce the results reported in our technical report, the evaluation program and usage guide have been prepared and are available at the following links.: [Math Eval](https://github.com/WeiboAI/VibeThinker/blob/main/eval/math/README.md) and [Code Eval](https://github.com/WeiboAI/VibeThinker/blob/main/eval/code/README.md).

Sample responses from some benchmarks:[here](https://drive.google.com/drive/folders/1qom754QSjujDI98Wv8LIKTaTszPkAN6q?usp=drive_link).

## Usage Guidelines

**We recommend using this model for competitive-style math and coding problems.**

To facilitate quick verification by the community, we recommend the following parameter settings: **temperature: 0.6 or 1.0, max token length: 40960, top\_p: 0.95, top\_k: -1.**

## Quick Start

Required: **transformers>=4.54.0**

Recommended for better inference performance: **vLLM==0.10.1 or SGLang>=0.4.9.post6**

Here is a code snippet to show you how to use the chat model with transformers:

```
from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig

class VibeThinker:
    def __init__(self, model_path):
        self.model_path = model_path
        self.model = AutoModelForCausalLM.from_pretrained(
            self.model_path,
            low_cpu_mem_usage=True,
            torch_dtype="bfloat16",
            device_map="auto"
        )
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_path, trust_remote_code=True)

    def infer_text(self, prompt):
        messages = [
            {"role": "user", "content": prompt}
        ]
        text = self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
        model_inputs = self.tokenizer([text], return_tensors="pt").to(self.model.device)

        text = self.tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )
        model_inputs = self.tokenizer([text], return_tensors="pt").to(self.model.device)

        generation_config = dict(
            max_new_tokens=40960,
            do_sample=True,
            temperature=0.6, # 0.6 or 1.0, you can set it according to your needs
            top_p=0.95,
            top_k=None # in vLLM or SGlang, please set top_k to -1, it means skip top_k for sampling
        )
        generated_ids = self.model.generate(
            **model_inputs,
            generation_config=GenerationConfig(**generation_config)
        )
        generated_ids = [
            output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
        ]

        response = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]

        return response

if __name__ == '__main__':
    model = VibeThinker('Your model path')
    prompt = 'Your Prompt'
    print(model.infer_text(prompt))
```

## License

This code repository is licensed under [the MIT License](https://github.com/WeiboAI/VibeThinker/blob/main/LICENSE).

## Citations

If you use VibeThinker in your research or product, please cite:

```
@misc{xu2025tinymodelbiglogic,
      title={Tiny Model, Big Logic: Diversity-Driven Optimization Elicits Large-Model Reasoning Ability in VibeThinker-1.5B}, 
      author={Sen Xu and Yi Zhou and Wei Wang and Jixin Min and Zhibin Yin and Yingwei Dai and Shixi Liu and Lianyu Pang and Yirong Chen and Junlin Zhang},
      year={2025},
      eprint={2511.06221},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2511.06221}, 
}
```

## Releases

No releases published

## Packages

No packages published  

## Languages

- [Python 91.9%](https://github.com/WeiboAI/VibeThinker/search?l=python)
- [Shell 8.1%](https://github.com/WeiboAI/VibeThinker/search?l=shell)